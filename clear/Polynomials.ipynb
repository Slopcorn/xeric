{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing polynomials with strange ways\n",
    "\n",
    "Author: Raido Everest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scipy minimize appears to work locally - depending on the starting point, we may arrive\n",
    "# at a different end position. This might bias end results toward methods that initialize\n",
    "# in many different places, but I highly doubt it makes much of a difference here.\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize  # checking goodness of result compared to scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate functions to test on\n",
    "def quartic():\n",
    "    # default ranges for variables too\n",
    "    a, b = random.random() * 4.9 + 0.1, random.random() * 10 - 5\n",
    "    c, d = random.random() * 40 - 20, random.random() * 500 - 250\n",
    "    \n",
    "    return lambda x: a * x**4 + b * x**3 + c * x**2 + d * x\n",
    "\n",
    "# Making an nd-quartic function to test higher dimensionalities.\n",
    "# For the sake of generality, this should be used for the single variable case as well.\n",
    "# n - how many inputs the function takes\n",
    "# outputs the sum of n random quartic functions\n",
    "def quartic_n(n):\n",
    "    fs = [quartic() for _ in range(n)]\n",
    "    return lambda answers: sum(map(lambda pair: pair[0](pair[1]), zip(fs, answers)))\n",
    "\n",
    "# Example scipy optimization of a 4d quartic function:\n",
    "# minimize(quartic_n(4), (0,0,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main function that returns the best set of inputs it finds.\n",
    "# f - the function.\n",
    "# n - input dimensionality\n",
    "# k - population size\n",
    "# scaling - the scaling parameter when creating a new input set\n",
    "# loops   - how many loops it will do before giving up finding a better solution\n",
    "# Outputs the minimum value of the function that it found and the necessary input for it\n",
    "def diff_evo(f, n, k = 80, scaling = 0.5, loops=25):\n",
    "    # Create initial input set\n",
    "    pop       = create_population(n, k)\n",
    "    fitnesses = calculate_fitness(f, pop)\n",
    "    best, bestval = getbest(pop, fitnesses)   # pair of best input and its value\n",
    "    \n",
    "    loops_since_improvement = 0  # Keep it going until it's not working anymore.\n",
    "    while loops_since_improvement < loops:\n",
    "        loops_since_improvement += 1\n",
    "        \n",
    "        # Create next population by mutating previous one\n",
    "        newpop       = create_next_population(pop, scaling)\n",
    "        newfitnesses = calculate_fitness(f, newpop)\n",
    "        nextbest, nextbestval = getbest(newpop, newfitnesses)\n",
    "        \n",
    "        # Keep track of what the best outcome is\n",
    "        if nextbestval < bestval:\n",
    "            best, bestval = nextbest, nextbestval\n",
    "            loops_since_improvement = 0\n",
    "        \n",
    "        # Always choose the better one of the two choices to represent the 'next generation'\n",
    "        for i in range(k):\n",
    "            if newfitnesses[i] < fitnesses[i]:  # if something must be changed\n",
    "                pop[i], fitnesses[i] = newpop[i], newfitnesses[i]\n",
    "    \n",
    "    # Return the best value and its inputs\n",
    "    return bestval, best\n",
    "\n",
    "# Creates a population not knowing any previous information\n",
    "# n - dimensionality of output\n",
    "# k - population size\n",
    "def create_population(n, k):\n",
    "    # Arbitrary range, but should be fine for the time being.\n",
    "    return [[random.random() * 200 - 100 for _ in range(n)] for _ in range(k)]\n",
    "\n",
    "# Creates the next generation of input sets\n",
    "# pop - the old population\n",
    "# scaling - the scaling parameter\n",
    "def create_next_population(pop, scaling = 0.5):\n",
    "    dim = len(pop[0])\n",
    "    n = len(pop)\n",
    "    \n",
    "    newpop = [None] * n\n",
    "    for i in range(n):\n",
    "        a, b = random.randint(0, n-1), random.randint(0, n-1)  # Indices of two random elements\n",
    "        diff = [(pop[a][d] - pop[b][d]) for d in range(dim)]   # Difference of two random input vectors\n",
    "        newpop[i] = [pop[i][d] + diff[d] * scaling for d in range(dim)]  # Mutated input has been created\n",
    "    \n",
    "    return newpop\n",
    "\n",
    "# Just makes a list of evaluation results\n",
    "def calculate_fitness(f, pop):\n",
    "    return [f(inputs) for inputs in pop]\n",
    "\n",
    "# Given a population and fitnesses, returns the best element and its fitness.\n",
    "def getbest(pop, fitnesses):\n",
    "    best, bestfitness = pop[0], fitnesses[0]\n",
    "    for i in range(1, len(fitnesses)):\n",
    "        if fitnesses[i] < bestfitness:\n",
    "            best, bestfitness = pop[i], fitnesses[i]\n",
    "    return best, bestfitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f - the function.\n",
    "# n - input dimensionality\n",
    "# k - population size\n",
    "# scaling - the scaling parameter when creating a new input set\n",
    "# loops   - how many loops it will do before giving up finding a better solution\n",
    "# Outputs the minimum value of the function that it found and the necessary input for it\n",
    "def pso(f, n, k=25, loops=25):\n",
    "    # Create initial population - including velocity, personal best locations\n",
    "    pop, velocity, pb_locs = create_pso(n, k)\n",
    "    # Also calculate personal best actual values.\n",
    "    pb_vals = calculate_fitness(f, pb_locs)\n",
    "    vals    = pb_vals[::]\n",
    "    g_best_loc, g_best_val = getbest(pop, vals)\n",
    "    \n",
    "    loops_since_improvement = 0\n",
    "    while loops_since_improvement < loops:\n",
    "        loops_since_improvement += 1\n",
    "        # Create the next generation - updates population, velocity\n",
    "        iterate_pso(pop, velocity, pb_locs, g_best_loc)\n",
    "        # Now update values, personal bests, global bests\n",
    "        vals = calculate_fitness(f, pop)\n",
    "        update_personal_best(pb_vals, pb_locs, vals, pop)\n",
    "        next_best_loc, next_best_val = getbest(pop, vals)\n",
    "        if next_best_val < g_best_val:\n",
    "            loops_since_improvement = 0\n",
    "            g_best_loc, g_best_val = next_best_loc, next_best_val\n",
    "        \n",
    "    return g_best_val, g_best_loc  # best output and input\n",
    "\n",
    "# n - input dimensionality\n",
    "# k - population size\n",
    "def create_pso(n, k):\n",
    "    pop = create_population(n, k)  # Just use the same population init as DE\n",
    "    velocity = norm(create_population(n, k), 10)\n",
    "    pb_locs  = pop[::]\n",
    "    return pop, velocity, pb_locs\n",
    "\n",
    "# Iterates the PSO state.\n",
    "# pop - current locations\n",
    "# velocity - how fast we are moving and where\n",
    "# pb_locs - the best positions value wise each element has been to\n",
    "# best_loc - globally the best position that everybody also wants to move toward\n",
    "def iterate_pso(pop, velocity, pb_locs, best_loc, c1=0.5, c2=0.5):\n",
    "    for i in range(len(pop)):\n",
    "        z1, z2 = random.random(), random.random()\n",
    "        velocity[i] = list(np.add(velocity[i],\n",
    "                                  np.add(c1*z1*np.subtract(pb_locs[i], pop[i]), c2*z2*np.subtract(best_loc, pop[i]))))\n",
    "        pop[i] = list(np.add(pop[i], velocity[i]))\n",
    "    \n",
    "    if random.random() < 0.1:\n",
    "        norm(velocity, 10)  # I will basically reset the speed my swarm moves at randomly - seems to help...\n",
    "    \n",
    "# does what it says\n",
    "def update_personal_best(pb_vals, pb_locs, vals, locs):\n",
    "    for i in range(len(vals)):\n",
    "        if vals[i] < pb_vals[i]:\n",
    "            pb_vals[i], pb_locs[i] = vals[i], locs[i]\n",
    "    \n",
    "# updates a list of vectors in place such that they become unit vectors\n",
    "# vectors - list of vectors that all have the same dimensions\n",
    "def norm(vectors, tolength=1):\n",
    "    if len(vectors) == 0:\n",
    "        return vectors\n",
    "    dim = len(vectors[0])\n",
    "    # length of vector is the sqrt of its dot product with itself\n",
    "    # simply divide each component with that value\n",
    "    for i in range(len(vectors)):\n",
    "        length = np.dot(vectors[i], vectors[i])**0.5\n",
    "        for j in range(dim):\n",
    "            vectors[i][j] /= length * tolength\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Goodness of Differential Evolution\n",
    "\n",
    "I expect scipy and diff_evo to be pretty close overall by quality of result. Turns out, they are, at least in this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bunch of functions. Use scipy and diff_evo to find optimal solutions.\n",
    "# Arbitrarily choose amount of functions for each dimensionality.\n",
    "functions = 10\n",
    "\n",
    "print('Measuring difference of scipy and diff_evo - the higher, the better for DE')\n",
    "for dimensions in range(1,5):\n",
    "    print(f'Testing out {dimensions} dimensions...')\n",
    "    for _ in range(functions):\n",
    "        function = quartic_n(dimensions)\n",
    "\n",
    "        sp_ans = minimize(function, [0] * dimensions)\n",
    "        sp_bestval, sp_bestinput = sp_ans.fun, sp_ans.x\n",
    "\n",
    "        de_bestval, de_bestinput = diff_evo(function, dimensions)\n",
    "\n",
    "        print(f'Difference between scipy and diffevo: {sp_bestval - de_bestval}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Goodness of Particle Swarm Optimization\n",
    "\n",
    "It's not bad. Sometimes gets a really good result in the end, thousands below the scipy default optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bunch of functions. Use scipy and diff_evo to find optimal solutions.\n",
    "# Arbitrarily choose amount of functions for each dimensionality.\n",
    "functions = 10\n",
    "\n",
    "print('Measuring difference of scipy and PSO - the higher, the better for PSO')\n",
    "for dimensions in range(1,5):\n",
    "    print(f'Testing out {dimensions} dimensions...')\n",
    "    for _ in range(functions):\n",
    "        function = quartic_n(dimensions)\n",
    "\n",
    "        sp_ans = minimize(function, [0] * dimensions)\n",
    "        sp_bestval, sp_bestinput = sp_ans.fun, sp_ans.x\n",
    "\n",
    "        pso_bestval, pso_bestinput = pso(function, dimensions)\n",
    "\n",
    "        print(f'Difference between scipy and PSO: {sp_bestval - pso_bestval}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Goodness of Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Goodness of Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
